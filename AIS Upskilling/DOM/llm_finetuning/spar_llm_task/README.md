Please complete the following take-home task and reply to this email with a link to a GitHub repo by [deadline]. The repo should include your code and a README describing what you did and your results.

Task: Use a Runpod GPU to finetune a huggingface transformer language model of your choice on a dataset of your choice, then evaluate the effect of the finetuning by running some of the same prompts on the pre- and post-finetuning models.

In your README, it would be nice to see one or more plots (including train loss) and a few examples of how the model’s responses change due to training, and ideally you would be demonstrating that the finetuning successfully achieved some simple desired behavior change. However, I also don’t want you to spend too much time or money on this task, so it’s fine if you do not check all these boxes.

This will likely require you to spend a few dollars on Runpod. Sorry about that, I am not planning to reimburse this. Let me know if this is a problem and I can try to help. (Please don’t spend more than $10; ideally you would spend significantly less than that.)

Feel free to create/use a very small train dataset to save money and increase iteration speed. This may mean you don’t get good generalization, but train loss should be going down.

You may use any resources you want, including LLMs, the internet, and asking people for help. (Just don’t ask anyone else to do the task for you.)

I’m hoping this task takes <2.5 hours (including the writeup), but it likely depends on your prior experience with the relevant tools. I encourage you to stop coding after ~2 hours or as soon as you have achieved the bare minimum described above and focus on the writeup after that.

Please make the writeup both concise and clear. I would like to spend <=5 minutes reading each submission.
